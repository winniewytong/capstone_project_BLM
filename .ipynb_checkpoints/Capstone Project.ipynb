{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s3fs\n",
      "  Downloading s3fs-0.4.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /Users/wtong/anaconda3/lib/python3.7/site-packages (from s3fs) (1.15.39)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /Users/wtong/anaconda3/lib/python3.7/site-packages (from s3fs) (0.7.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/wtong/anaconda3/lib/python3.7/site-packages (from botocore>=1.12.91->s3fs) (0.9.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/wtong/anaconda3/lib/python3.7/site-packages (from botocore>=1.12.91->s3fs) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/wtong/anaconda3/lib/python3.7/site-packages (from botocore>=1.12.91->s3fs) (0.14)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /Users/wtong/anaconda3/lib/python3.7/site-packages (from botocore>=1.12.91->s3fs) (1.25.8)\n",
      "Requirement already satisfied: six>=1.5 in /Users/wtong/anaconda3/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.12.91->s3fs) (1.14.0)\n",
      "Installing collected packages: s3fs\n",
      "Successfully installed s3fs-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month,dayofweek, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import *\n",
    "import logging\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "\n",
    "This dataset pulls together data from several different sources related to police-related violence in the United States. The dataset currently includes these types of data:\n",
    "\n",
    "- Police shootings\n",
    "- Citizen fatalities involving police\n",
    "- Police officer deaths suffered in the line of duty\n",
    "- Summary statistics by city on people killed, arrests, population\n",
    "- City poopulation\n",
    "- Police department headcounts\n",
    "- Detailed crimes and arrests for the prime city in the four largest metro areas.\n",
    "- Locations for all BLM protests since May 25, 2020\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Names of states in the US\n",
    "- The dataset below shows the name and abbreviation of states in the US "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "us_state = \"s3://datalake-blm/raw/us_state.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_df = pd.read_csv(us_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   state         50 non-null     object\n",
      " 1   state_abbrev  50 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 928.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "us_state_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_abbrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state state_abbrev\n",
       "0     Alabama            AL\n",
       "1      Alaska            AK\n",
       "2     Arizona            AZ\n",
       "3    Arkansas            AR\n",
       "4  California            CA"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_state_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state           50\n",
       "state_abbrev    50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_state_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Budgets in different states in the US \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "budgets = \"s3://datalake-blm/raw/budgets.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "budgets_df = pd.read_csv(budgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>city_name</th>\n",
       "      <th>id_city</th>\n",
       "      <th>city_population</th>\n",
       "      <th>cpi</th>\n",
       "      <th>rev_total_city</th>\n",
       "      <th>rev_general_city</th>\n",
       "      <th>intergovt_rev_city</th>\n",
       "      <th>igr_federal_city</th>\n",
       "      <th>igr_state_city</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_other_offsets</th>\n",
       "      <th>cash_other_bonds</th>\n",
       "      <th>cash_other_other</th>\n",
       "      <th>county_name</th>\n",
       "      <th>id_county</th>\n",
       "      <th>county_population</th>\n",
       "      <th>relationship_city_school</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>districts_in_city</th>\n",
       "      <th>consolidated_govt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1977</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>174500</td>\n",
       "      <td>4.044885</td>\n",
       "      <td>5342.24</td>\n",
       "      <td>4956.92</td>\n",
       "      <td>2148.77</td>\n",
       "      <td>279.32</td>\n",
       "      <td>1869.46</td>\n",
       "      <td>...</td>\n",
       "      <td>178.51</td>\n",
       "      <td>787.93</td>\n",
       "      <td>691.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36855.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>177000</td>\n",
       "      <td>3.759509</td>\n",
       "      <td>5948.99</td>\n",
       "      <td>5490.05</td>\n",
       "      <td>2468.11</td>\n",
       "      <td>403.24</td>\n",
       "      <td>2064.86</td>\n",
       "      <td>...</td>\n",
       "      <td>187.53</td>\n",
       "      <td>1395.82</td>\n",
       "      <td>1158.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36804.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>179600</td>\n",
       "      <td>3.376308</td>\n",
       "      <td>6158.68</td>\n",
       "      <td>5746.64</td>\n",
       "      <td>2573.34</td>\n",
       "      <td>496.97</td>\n",
       "      <td>2076.37</td>\n",
       "      <td>...</td>\n",
       "      <td>249.03</td>\n",
       "      <td>1812.04</td>\n",
       "      <td>1314.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36757.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>178800</td>\n",
       "      <td>2.974757</td>\n",
       "      <td>5654.93</td>\n",
       "      <td>5210.77</td>\n",
       "      <td>2313.62</td>\n",
       "      <td>371.46</td>\n",
       "      <td>1942.16</td>\n",
       "      <td>...</td>\n",
       "      <td>986.73</td>\n",
       "      <td>1330.72</td>\n",
       "      <td>1572.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>174431</td>\n",
       "      <td>2.696590</td>\n",
       "      <td>6192.83</td>\n",
       "      <td>5736.81</td>\n",
       "      <td>2771.43</td>\n",
       "      <td>338.76</td>\n",
       "      <td>2432.67</td>\n",
       "      <td>...</td>\n",
       "      <td>977.32</td>\n",
       "      <td>1549.51</td>\n",
       "      <td>1669.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34557.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 662 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      city_name     id_city  city_population       cpi  rev_total_city  \\\n",
       "0  1977  AK: Anchorage  22002001.0           174500  4.044885         5342.24   \n",
       "1  1978  AK: Anchorage  22002001.0           177000  3.759509         5948.99   \n",
       "2  1979  AK: Anchorage  22002001.0           179600  3.376308         6158.68   \n",
       "3  1980  AK: Anchorage  22002001.0           178800  2.974757         5654.93   \n",
       "4  1981  AK: Anchorage  22002001.0           174431  2.696590         6192.83   \n",
       "\n",
       "   rev_general_city  intergovt_rev_city  igr_federal_city  igr_state_city  \\\n",
       "0           4956.92             2148.77            279.32         1869.46   \n",
       "1           5490.05             2468.11            403.24         2064.86   \n",
       "2           5746.64             2573.34            496.97         2076.37   \n",
       "3           5210.77             2313.62            371.46         1942.16   \n",
       "4           5736.81             2771.43            338.76         2432.67   \n",
       "\n",
       "   ...  cash_other_offsets  cash_other_bonds  cash_other_other  county_name  \\\n",
       "0  ...              178.51            787.93            691.32          NaN   \n",
       "1  ...              187.53           1395.82           1158.01          NaN   \n",
       "2  ...              249.03           1812.04           1314.62          NaN   \n",
       "3  ...              986.73           1330.72           1572.66          NaN   \n",
       "4  ...              977.32           1549.51           1669.55          NaN   \n",
       "\n",
       "   id_county  county_population  relationship_city_school  enrollment  \\\n",
       "0        NaN                NaN                       4.0     36855.0   \n",
       "1        NaN                NaN                       4.0     36804.0   \n",
       "2        NaN                NaN                       4.0     36757.0   \n",
       "3        NaN                NaN                       4.0     36008.0   \n",
       "4        NaN                NaN                       4.0     34557.0   \n",
       "\n",
       "   districts_in_city  consolidated_govt  \n",
       "0                NaN                1.0  \n",
       "1                NaN                1.0  \n",
       "2                NaN                1.0  \n",
       "3                NaN                1.0  \n",
       "4                NaN                1.0  \n",
       "\n",
       "[5 rows x 662 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budgets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6232 entries, 0 to 6231\n",
      "Columns: 662 entries, year to consolidated_govt\n",
      "dtypes: float64(658), int64(2), object(2)\n",
      "memory usage: 31.5+ MB\n"
     ]
    }
   ],
   "source": [
    "budgets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This dataset has has more than 600 columns and it is not easy to inspect all the columns. \n",
    "- I might just extract the population of each city so I can map this information up with other data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                        6232\n",
       "city_name                   6232\n",
       "id_city                     6191\n",
       "city_population             6232\n",
       "cpi                         6150\n",
       "                            ... \n",
       "county_population           5418\n",
       "relationship_city_school    6150\n",
       "enrollment                  6196\n",
       "districts_in_city           4741\n",
       "consolidated_govt           6150\n",
       "Length: 662, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budgets_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Police Killings \n",
    "- The dataset below shows the information of civilians killed by police in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_killings = 's3://datalake-blm/raw/police_killings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_killings_df = pd.read_csv(police_killings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Victim's name</th>\n",
       "      <th>Victim's age</th>\n",
       "      <th>Victim's gender</th>\n",
       "      <th>Victim's race</th>\n",
       "      <th>URL of image of victim</th>\n",
       "      <th>Date of Incident (month/day/year)</th>\n",
       "      <th>Street Address of Incident</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 56</th>\n",
       "      <th>Unnamed: 57</th>\n",
       "      <th>Unnamed: 58</th>\n",
       "      <th>Unnamed: 59</th>\n",
       "      <th>Unnamed: 60</th>\n",
       "      <th>Unnamed: 61</th>\n",
       "      <th>Unnamed: 62</th>\n",
       "      <th>Unnamed: 63</th>\n",
       "      <th>Unnamed: 64</th>\n",
       "      <th>Unnamed: 65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eric M. Tellez</td>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>https://fatalencounters.org/wp-content/uploads...</td>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>Broad St.</td>\n",
       "      <td>Globe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85501.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name withheld by police</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>7239-7411 I-40</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>AR</td>\n",
       "      <td>38103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Terry Hudson</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>3600 N 24th St</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>NE</td>\n",
       "      <td>68110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik Williams</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>30800 14th Avenue South</td>\n",
       "      <td>Federal Way</td>\n",
       "      <td>WA</td>\n",
       "      <td>98003.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frederick Perkins</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>17057 N Outer 40 Rd</td>\n",
       "      <td>Chesterfield</td>\n",
       "      <td>MO</td>\n",
       "      <td>63005.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Victim's name Victim's age Victim's gender Victim's race  \\\n",
       "0           Eric M. Tellez           28            Male         White   \n",
       "1  Name withheld by police          NaN            Male  Unknown race   \n",
       "2             Terry Hudson           57            Male         Black   \n",
       "3           Malik Williams           23            Male         Black   \n",
       "4        Frederick Perkins           37            Male         Black   \n",
       "\n",
       "                              URL of image of victim  \\\n",
       "0  https://fatalencounters.org/wp-content/uploads...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "  Date of Incident (month/day/year) Street Address of Incident          City  \\\n",
       "0                        31/12/2019                 Broad St.          Globe   \n",
       "1                        31/12/2019             7239-7411 I-40       Memphis   \n",
       "2                        31/12/2019             3600 N 24th St         Omaha   \n",
       "3                        31/12/2019    30800 14th Avenue South   Federal Way   \n",
       "4                        31/12/2019        17057 N Outer 40 Rd  Chesterfield   \n",
       "\n",
       "  State  Zipcode  ... Unnamed: 56 Unnamed: 57 Unnamed: 58 Unnamed: 59  \\\n",
       "0    AZ  85501.0  ...         NaN         NaN         NaN         NaN   \n",
       "1    AR  38103.0  ...         NaN         NaN         NaN         NaN   \n",
       "2    NE  68110.0  ...         NaN         NaN         NaN         NaN   \n",
       "3    WA  98003.0  ...         NaN         NaN         NaN         NaN   \n",
       "4    MO  63005.0  ...         NaN         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 60 Unnamed: 61 Unnamed: 62 Unnamed: 63 Unnamed: 64 Unnamed: 65  \n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Victim's name             7411\n",
       "Victim's age                87\n",
       "Victim's gender              4\n",
       "Victim's race                8\n",
       "URL of image of victim    4191\n",
       "                          ... \n",
       "Unnamed: 61                  0\n",
       "Unnamed: 62                  0\n",
       "Unnamed: 63                  0\n",
       "Unnamed: 64                  0\n",
       "Unnamed: 65                  0\n",
       "Length: 66, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7907 entries, 0 to 7906\n",
      "Data columns (total 66 columns):\n",
      " #   Column                                                                                                                                                                      Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                                                                      --------------  -----  \n",
      " 0   Victim's name                                                                                                                                                               7663 non-null   object \n",
      " 1   Victim's age                                                                                                                                                                7596 non-null   object \n",
      " 2   Victim's gender                                                                                                                                                             7655 non-null   object \n",
      " 3   Victim's race                                                                                                                                                               7663 non-null   object \n",
      " 4   URL of image of victim                                                                                                                                                      4200 non-null   object \n",
      " 5   Date of Incident (month/day/year)                                                                                                                                           7663 non-null   object \n",
      " 6   Street Address of Incident                                                                                                                                                  7580 non-null   object \n",
      " 7   City                                                                                                                                                                        7657 non-null   object \n",
      " 8   State                                                                                                                                                                       7663 non-null   object \n",
      " 9   Zipcode                                                                                                                                                                     7624 non-null   float64\n",
      " 10  County                                                                                                                                                                      7648 non-null   object \n",
      " 11  Agency responsible for death                                                                                                                                                7647 non-null   object \n",
      " 12  Cause of death                                                                                                                                                              7663 non-null   object \n",
      " 13  A brief description of the circumstances surrounding the death                                                                                                              7643 non-null   object \n",
      " 14  Official disposition of death (justified or other)                                                                                                                          7407 non-null   object \n",
      " 15  Criminal Charges?                                                                                                                                                           7663 non-null   object \n",
      " 16  Link to news article or photo of official document                                                                                                                          7651 non-null   object \n",
      " 17  Symptoms of mental illness?                                                                                                                                                 7652 non-null   object \n",
      " 18  Unarmed                                                                                                                                                                     7663 non-null   object \n",
      " 19  Alleged Weapon (Source: WaPo)                                                                                                                                               7663 non-null   object \n",
      " 20  Alleged Threat Level (Source: WaPo)                                                                                                                                         5281 non-null   object \n",
      " 21  Fleeing (Source: WaPo)                                                                                                                                                      5047 non-null   object \n",
      " 22  Body Camera (Source: WaPo)                                                                                                                                                  4794 non-null   object \n",
      " 23  WaPo ID (If included in WaPo database)                                                                                                                                      4878 non-null   float64\n",
      " 24  Off-Duty Killing?                                                                                                                                                           226 non-null    object \n",
      " 25  Geography (via Trulia methodology based on zipcode population density: http://jedkolko.com/wp-content/uploads/2015/05/full-ZCTA-urban-suburban-rural-classification.xlsx )  7596 non-null   object \n",
      " 26  ID                                                                                                                                                                          7663 non-null   float64\n",
      " 27  Unnamed: 27                                                                                                                                                                 0 non-null      float64\n",
      " 28  Unnamed: 28                                                                                                                                                                 0 non-null      float64\n",
      " 29  Unnamed: 29                                                                                                                                                                 0 non-null      float64\n",
      " 30  Unnamed: 30                                                                                                                                                                 0 non-null      float64\n",
      " 31  Unnamed: 31                                                                                                                                                                 0 non-null      float64\n",
      " 32  Unnamed: 32                                                                                                                                                                 0 non-null      float64\n",
      " 33  Unnamed: 33                                                                                                                                                                 0 non-null      float64\n",
      " 34  Unnamed: 34                                                                                                                                                                 0 non-null      float64\n",
      " 35  Unnamed: 35                                                                                                                                                                 0 non-null      float64\n",
      " 36  Unnamed: 36                                                                                                                                                                 0 non-null      float64\n",
      " 37  Unnamed: 37                                                                                                                                                                 0 non-null      float64\n",
      " 38  Unnamed: 38                                                                                                                                                                 0 non-null      float64\n",
      " 39  Unnamed: 39                                                                                                                                                                 0 non-null      float64\n",
      " 40  Unnamed: 40                                                                                                                                                                 0 non-null      float64\n",
      " 41  Unnamed: 41                                                                                                                                                                 0 non-null      float64\n",
      " 42  Unnamed: 42                                                                                                                                                                 0 non-null      float64\n",
      " 43  Unnamed: 43                                                                                                                                                                 0 non-null      float64\n",
      " 44  Unnamed: 44                                                                                                                                                                 0 non-null      float64\n",
      " 45  Unnamed: 45                                                                                                                                                                 0 non-null      float64\n",
      " 46  Unnamed: 46                                                                                                                                                                 0 non-null      float64\n",
      " 47  Unnamed: 47                                                                                                                                                                 0 non-null      float64\n",
      " 48  Unnamed: 48                                                                                                                                                                 0 non-null      float64\n",
      " 49  Unnamed: 49                                                                                                                                                                 0 non-null      float64\n",
      " 50  Unnamed: 50                                                                                                                                                                 0 non-null      float64\n",
      " 51  Unnamed: 51                                                                                                                                                                 0 non-null      float64\n",
      " 52  Unnamed: 52                                                                                                                                                                 0 non-null      float64\n",
      " 53  Unnamed: 53                                                                                                                                                                 0 non-null      float64\n",
      " 54  Unnamed: 54                                                                                                                                                                 0 non-null      float64\n",
      " 55  Unnamed: 55                                                                                                                                                                 0 non-null      float64\n",
      " 56  Unnamed: 56                                                                                                                                                                 0 non-null      float64\n",
      " 57  Unnamed: 57                                                                                                                                                                 0 non-null      float64\n",
      " 58  Unnamed: 58                                                                                                                                                                 0 non-null      float64\n",
      " 59  Unnamed: 59                                                                                                                                                                 0 non-null      float64\n",
      " 60  Unnamed: 60                                                                                                                                                                 0 non-null      float64\n",
      " 61  Unnamed: 61                                                                                                                                                                 0 non-null      float64\n",
      " 62  Unnamed: 62                                                                                                                                                                 0 non-null      float64\n",
      " 63  Unnamed: 63                                                                                                                                                                 0 non-null      float64\n",
      " 64  Unnamed: 64                                                                                                                                                                 0 non-null      float64\n",
      " 65  Unnamed: 65                                                                                                                                                                 0 non-null      float64\n",
      "dtypes: float64(42), object(24)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "police_killings_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This dataset has so many unnamed columns that have no values. I will need to delete them.\n",
    "- Some columns have null values. Need to explore that a bit more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Police Deaths\n",
    "- The dataset below shows information of police who got killed when on duty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_deaths = 's3://datalake-blm/raw/police_deaths_538.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_deaths_df = pd.read_csv(police_deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22800 entries, 0 to 22799\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   person       22800 non-null  object\n",
      " 1   dept         22800 non-null  object\n",
      " 2   eow          22800 non-null  object\n",
      " 3   cause        22800 non-null  object\n",
      " 4   cause_short  22800 non-null  object\n",
      " 5   date         22800 non-null  object\n",
      " 6   year         22800 non-null  int64 \n",
      " 7   canine       22800 non-null  bool  \n",
      " 8   dept_name    22800 non-null  object\n",
      " 9   state        22800 non-null  object\n",
      "dtypes: bool(1), int64(1), object(8)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "police_deaths_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This datasets looks more clean. It doesn't need a lot of further curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>dept</th>\n",
       "      <th>eow</th>\n",
       "      <th>cause</th>\n",
       "      <th>cause_short</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>canine</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Constable Darius Quimby</td>\n",
       "      <td>Albany County Constable's Office, NY</td>\n",
       "      <td>EOW: Monday, January 3, 1791</td>\n",
       "      <td>Cause of Death: Gunfire</td>\n",
       "      <td>Gunfire</td>\n",
       "      <td>1791-01-03</td>\n",
       "      <td>1791</td>\n",
       "      <td>False</td>\n",
       "      <td>Albany County Constable's Office</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sheriff Cornelius Hogeboom</td>\n",
       "      <td>Columbia County Sheriff's Office, NY</td>\n",
       "      <td>EOW: Saturday, October 22, 1791</td>\n",
       "      <td>Cause of Death: Gunfire</td>\n",
       "      <td>Gunfire</td>\n",
       "      <td>1791-10-22</td>\n",
       "      <td>1791</td>\n",
       "      <td>False</td>\n",
       "      <td>Columbia County Sheriff's Office</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deputy Sheriff Isaac Smith</td>\n",
       "      <td>Westchester County Sheriff's Department, NY</td>\n",
       "      <td>EOW: Thursday, May 17, 1792</td>\n",
       "      <td>Cause of Death: Gunfire</td>\n",
       "      <td>Gunfire</td>\n",
       "      <td>1792-05-17</td>\n",
       "      <td>1792</td>\n",
       "      <td>False</td>\n",
       "      <td>Westchester County Sheriff's Department</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marshal Robert Forsyth</td>\n",
       "      <td>United States Department of Justice - United S...</td>\n",
       "      <td>EOW: Saturday, January 11, 1794</td>\n",
       "      <td>Cause of Death: Gunfire</td>\n",
       "      <td>Gunfire</td>\n",
       "      <td>1794-01-11</td>\n",
       "      <td>1794</td>\n",
       "      <td>False</td>\n",
       "      <td>United States Department of Justice - United S...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sheriff Robert Maxwell</td>\n",
       "      <td>Greenville County Sheriff's Office, SC</td>\n",
       "      <td>EOW: Sunday, November 12, 1797</td>\n",
       "      <td>Cause of Death: Gunfire</td>\n",
       "      <td>Gunfire</td>\n",
       "      <td>1797-11-12</td>\n",
       "      <td>1797</td>\n",
       "      <td>False</td>\n",
       "      <td>Greenville County Sheriff's Office</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       person  \\\n",
       "0     Constable Darius Quimby   \n",
       "1  Sheriff Cornelius Hogeboom   \n",
       "2  Deputy Sheriff Isaac Smith   \n",
       "3      Marshal Robert Forsyth   \n",
       "4      Sheriff Robert Maxwell   \n",
       "\n",
       "                                                dept  \\\n",
       "0               Albany County Constable's Office, NY   \n",
       "1               Columbia County Sheriff's Office, NY   \n",
       "2        Westchester County Sheriff's Department, NY   \n",
       "3  United States Department of Justice - United S...   \n",
       "4             Greenville County Sheriff's Office, SC   \n",
       "\n",
       "                               eow                    cause cause_short  \\\n",
       "0     EOW: Monday, January 3, 1791  Cause of Death: Gunfire     Gunfire   \n",
       "1  EOW: Saturday, October 22, 1791  Cause of Death: Gunfire     Gunfire   \n",
       "2      EOW: Thursday, May 17, 1792  Cause of Death: Gunfire     Gunfire   \n",
       "3  EOW: Saturday, January 11, 1794  Cause of Death: Gunfire     Gunfire   \n",
       "4   EOW: Sunday, November 12, 1797  Cause of Death: Gunfire     Gunfire   \n",
       "\n",
       "         date  year  canine  \\\n",
       "0  1791-01-03  1791   False   \n",
       "1  1791-10-22  1791   False   \n",
       "2  1792-05-17  1792   False   \n",
       "3  1794-01-11  1794   False   \n",
       "4  1797-11-12  1797   False   \n",
       "\n",
       "                                           dept_name state  \n",
       "0                   Albany County Constable's Office    NY  \n",
       "1                   Columbia County Sheriff's Office    NY  \n",
       "2            Westchester County Sheriff's Department    NY  \n",
       "3  United States Department of Justice - United S...    US  \n",
       "4                 Greenville County Sheriff's Office    SC  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_deaths_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person         22742\n",
       "dept            6528\n",
       "eow            17158\n",
       "cause             36\n",
       "cause_short       36\n",
       "date           17158\n",
       "year             202\n",
       "canine             2\n",
       "dept_name       5525\n",
       "state             60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_deaths_df.nunique()\n",
    "## Some names seem to have been duplicated. Will need to make sure I don't de-dupe important information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Protest data\n",
    "- The dataset below shows all BLM protests since 25th May 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "protest = 's3a://datalake-blm/raw/protests.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given it is a json file, I wanna use spark to explore it and print the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "protests_df = spark.read.json(protest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- geometry: struct (nullable = true)\n",
      " |    |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- properties: struct (nullable = true)\n",
      " |    |    |    |-- Alias: string (nullable = true)\n",
      " |    |    |    |-- Batch: string (nullable = true)\n",
      " |    |    |    |-- City: string (nullable = true)\n",
      " |    |    |    |-- Comments: string (nullable = true)\n",
      " |    |    |    |-- Country: string (nullable = true)\n",
      " |    |    |    |-- Date_Added: long (nullable = true)\n",
      " |    |    |    |-- Mailing_Abbreviation: string (nullable = true)\n",
      " |    |    |    |-- OBJECTID: long (nullable = true)\n",
      " |    |    |    |-- Region: string (nullable = true)\n",
      " |    |    |    |-- Search_Label: string (nullable = true)\n",
      " |    |    |    |-- X_Longitude: double (nullable = true)\n",
      " |    |    |    |-- Y_Latitude: double (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "protests_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given that this is a json file, I will need to flatten the columns to turn data into tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|            features|             type|\n",
      "+--------------------+-----------------+\n",
      "|[[[[-134.40678999...|FeatureCollection|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "protests_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Los Angeles crime data from 2001 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = 's3a://datalake-blm/raw/LA Crime_Data_from_2010_to_2019.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o92.load.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 20, localhost, executor driver): com.amazonaws.AmazonClientException: Unable to execute HTTP request: Timeout waiting for connection from pool\n\tat com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:454)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:232)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:3528)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObject(AmazonS3Client.java:1111)\n\tat org.apache.hadoop.fs.s3a.S3AInputStream.reopen(S3AInputStream.java:91)\n\tat org.apache.hadoop.fs.s3a.S3AInputStream.openIfNeeded(S3AInputStream.java:62)\n\tat org.apache.hadoop.fs.s3a.S3AInputStream.read(S3AInputStream.java:156)\n\tat java.io.DataInputStream.read(DataInputStream.java:149)\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)\n\tat org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)\n\tat org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:181)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)\n\tat scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$24.apply(RDD.scala:1167)\n\tat org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$24.apply(RDD.scala:1167)\n\tat org.apache.spark.SparkContext$$anonfun$36.apply(SparkContext.scala:2157)\n\tat org.apache.spark.SparkContext$$anonfun$36.apply(SparkContext.scala:2157)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool\n\tat org.apache.http.impl.conn.PoolingClientConnectionManager.leaseConnection(PoolingClientConnectionManager.java:231)\n\tat org.apache.http.impl.conn.PoolingClientConnectionManager$1.getConnection(PoolingClientConnectionManager.java:200)\n\tat sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.amazonaws.http.conn.ClientConnectionRequestFactory$Handler.invoke(ClientConnectionRequestFactory.java:70)\n\tat com.amazonaws.http.conn.$Proxy15.getConnection(Unknown Source)\n\tat org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:422)\n\tat org.apache.http.impl.client.AbstractHttpClient.doExecute(AbstractHttpClient.java:835)\n\tat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)\n\tat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)\n\tat com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:384)\n\t... 46 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD$$anonfun$aggregate$1.apply(RDD.scala:1169)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.aggregate(RDD.scala:1162)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$.infer(CSVInferSchema.scala:44)\n\tat org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.inferFromDataset(CSVDataSource.scala:261)\n\tat org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:237)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:68)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:63)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$6.apply(DataSource.scala:180)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$6.apply(DataSource.scala:180)\n\tat scala.Option.orElse(Option.scala:289)\n\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:179)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:373)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: com.amazonaws.AmazonClientException: Unable to execute HTTP request: Timeout waiting for connection from pool\n\tat com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:454)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:232)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:3528)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObject(AmazonS3Client.java:1111)\n\tat org.apache.hadoop.fs.s3a.S3AInputStream.reopen(S3AInputStream.java:91)\n\tat org.apache.hadoop.fs.s3a.S3AInputStream.openIfNeeded(S3AInputStream.java:62)\n\tat org.apache.hadoop.fs.s3a.S3AInputStream.read(S3AInputStream.java:156)\n\tat java.io.DataInputStream.read(DataInputStream.java:149)\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)\n\tat org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)\n\tat org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:181)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)\n\tat scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$24.apply(RDD.scala:1167)\n\tat org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$24.apply(RDD.scala:1167)\n\tat org.apache.spark.SparkContext$$anonfun$36.apply(SparkContext.scala:2157)\n\tat org.apache.spark.SparkContext$$anonfun$36.apply(SparkContext.scala:2157)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool\n\tat org.apache.http.impl.conn.PoolingClientConnectionManager.leaseConnection(PoolingClientConnectionManager.java:231)\n\tat org.apache.http.impl.conn.PoolingClientConnectionManager$1.getConnection(PoolingClientConnectionManager.java:200)\n\tat sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.amazonaws.http.conn.ClientConnectionRequestFactory$Handler.invoke(ClientConnectionRequestFactory.java:70)\n\tat com.amazonaws.http.conn.$Proxy15.getConnection(Unknown Source)\n\tat org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:422)\n\tat org.apache.http.impl.client.AbstractHttpClient.doExecute(AbstractHttpClient.java:835)\n\tat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)\n\tat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)\n\tat com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:384)\n\t... 46 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5ae9c08c46e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mla_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'com.databricks.spark.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o92.load.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 20, localhost, executor driver): com.amazonaws.AmazonClientException: Unable to execute HTTP request: Timeout waiting for connection from pool\n\tat com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:454)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:232)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:3528)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObject(AmazonS3Client.java:1111)\n\tat org.apache.hadoop.fs.s3a.S3AInputStream.reopen(S3AInputStream.java:91)\n\tat org.apache.hadoop.fs.s3a.S3AInputStream.openIfNeeded(S3AInputStream.java:62)\n\tat org.apache.hadoop.fs.s3a.S3AInputStream.read(S3AInputStream.java:156)\n\tat java.io.DataInputStream.read(DataInputStream.java:149)\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)\n\tat org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)\n\tat org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:181)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)\n\tat scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$24.apply(RDD.scala:1167)\n\tat org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$24.apply(RDD.scala:1167)\n\tat org.apache.spark.SparkContext$$anonfun$36.apply(SparkContext.scala:2157)\n\tat org.apache.spark.SparkContext$$anonfun$36.apply(SparkContext.scala:2157)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool\n\tat org.apache.http.impl.conn.PoolingClientConnectionManager.leaseConnection(PoolingClientConnectionManager.java:231)\n\tat org.apache.http.impl.conn.PoolingClientConnectionManager$1.getConnection(PoolingClientConnectionManager.java:200)\n\tat sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.amazonaws.http.conn.ClientConnectionRequestFactory$Handler.invoke(ClientConnectionRequestFactory.java:70)\n\tat com.amazonaws.http.conn.$Proxy15.getConnection(Unknown Source)\n\tat org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:422)\n\tat org.apache.http.impl.client.AbstractHttpClient.doExecute(AbstractHttpClient.java:835)\n\tat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)\n\tat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)\n\tat com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:384)\n\t... 46 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD$$anonfun$aggregate$1.apply(RDD.scala:1169)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.aggregate(RDD.scala:1162)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$.infer(CSVInferSchema.scala:44)\n\tat org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.inferFromDataset(CSVDataSource.scala:261)\n\tat org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:237)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:68)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:63)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$6.apply(DataSource.scala:180)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$6.apply(DataSource.scala:180)\n\tat scala.Option.orElse(Option.scala:289)\n\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:179)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:373)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: com.amazonaws.AmazonClientException: Unable to execute HTTP request: Timeout waiting for connection from pool\n\tat com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:454)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:232)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:3528)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObject(AmazonS3Client.java:1111)\n\tat org.apache.hadoop.fs.s3a.S3AInputStream.reopen(S3AInputStream.java:91)\n\tat org.apache.hadoop.fs.s3a.S3AInputStream.openIfNeeded(S3AInputStream.java:62)\n\tat org.apache.hadoop.fs.s3a.S3AInputStream.read(S3AInputStream.java:156)\n\tat java.io.DataInputStream.read(DataInputStream.java:149)\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)\n\tat org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)\n\tat org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:181)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)\n\tat scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$24.apply(RDD.scala:1167)\n\tat org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$24.apply(RDD.scala:1167)\n\tat org.apache.spark.SparkContext$$anonfun$36.apply(SparkContext.scala:2157)\n\tat org.apache.spark.SparkContext$$anonfun$36.apply(SparkContext.scala:2157)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool\n\tat org.apache.http.impl.conn.PoolingClientConnectionManager.leaseConnection(PoolingClientConnectionManager.java:231)\n\tat org.apache.http.impl.conn.PoolingClientConnectionManager$1.getConnection(PoolingClientConnectionManager.java:200)\n\tat sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.amazonaws.http.conn.ClientConnectionRequestFactory$Handler.invoke(ClientConnectionRequestFactory.java:70)\n\tat com.amazonaws.http.conn.$Proxy15.getConnection(Unknown Source)\n\tat org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:422)\n\tat org.apache.http.impl.client.AbstractHttpClient.doExecute(AbstractHttpClient.java:835)\n\tat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)\n\tat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)\n\tat com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:384)\n\t... 46 more\n"
     ]
    }
   ],
   "source": [
    "la_df = spark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2114699"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. New York Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ny = 's3a://datalake-blm/raw/NYPD_Arrests_Data__Historic_.json'\n",
    "ny = 's3a://datalake-blm/raw/NYPD_Arrests_Data__Historic_.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ny_df = spark.read.json(ny)\n",
    "ny_df = spark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+--------------------+-----+--------------+----------+----------+-----------+---------------+-----------------+---------+--------+--------------+----------+----------+------------------+------------------+--------------------+\n",
      "|ARREST_KEY|ARREST_DATE|PD_CD|             PD_DESC|KY_CD|     OFNS_DESC|  LAW_CODE|LAW_CAT_CD|ARREST_BORO|ARREST_PRECINCT|JURISDICTION_CODE|AGE_GROUP|PERP_SEX|     PERP_RACE|X_COORD_CD|Y_COORD_CD|          Latitude|         Longitude|             Lon_Lat|\n",
      "+----------+-----------+-----+--------------------+-----+--------------+----------+----------+-----------+---------------+-----------------+---------+--------+--------------+----------+----------+------------------+------------------+--------------------+\n",
      "| 190294601| 11/23/2018|  109|ASSAULT 2,1,UNCLA...|  106|FELONY ASSAULT|PL 1200512|         F|          B|             40|                0|    25-44|       M|         BLACK| 1008096.0|  233595.0|40.807816227000046|-73.91386266099995|POINT (-73.913862...|\n",
      "| 190266280| 11/21/2018|  665|                null| null|          null|PL 4902001|         F|          Q|            109|                0|    25-44|       M|BLACK HISPANIC| 1032084.0|  216954.0|40.762043893000055|-73.82732958099997|POINT (-73.827329...|\n",
      "+----------+-----------+-----+--------------------+-----+--------------+----------+----------+-----------+---------------+-----------------+---------+--------+--------------+----------+----------+------------------+------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ny_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- {: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ny_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550765"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Budgets \n",
    "- I want to extract the city_population column from this table and create a new column labelling the state of each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>city_name</th>\n",
       "      <th>id_city</th>\n",
       "      <th>city_population</th>\n",
       "      <th>cpi</th>\n",
       "      <th>rev_total_city</th>\n",
       "      <th>rev_general_city</th>\n",
       "      <th>intergovt_rev_city</th>\n",
       "      <th>igr_federal_city</th>\n",
       "      <th>igr_state_city</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_other_offsets</th>\n",
       "      <th>cash_other_bonds</th>\n",
       "      <th>cash_other_other</th>\n",
       "      <th>county_name</th>\n",
       "      <th>id_county</th>\n",
       "      <th>county_population</th>\n",
       "      <th>relationship_city_school</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>districts_in_city</th>\n",
       "      <th>consolidated_govt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1977</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>174500</td>\n",
       "      <td>4.044885</td>\n",
       "      <td>5342.24</td>\n",
       "      <td>4956.92</td>\n",
       "      <td>2148.77</td>\n",
       "      <td>279.32</td>\n",
       "      <td>1869.46</td>\n",
       "      <td>...</td>\n",
       "      <td>178.51</td>\n",
       "      <td>787.93</td>\n",
       "      <td>691.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36855.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>177000</td>\n",
       "      <td>3.759509</td>\n",
       "      <td>5948.99</td>\n",
       "      <td>5490.05</td>\n",
       "      <td>2468.11</td>\n",
       "      <td>403.24</td>\n",
       "      <td>2064.86</td>\n",
       "      <td>...</td>\n",
       "      <td>187.53</td>\n",
       "      <td>1395.82</td>\n",
       "      <td>1158.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36804.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 662 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      city_name     id_city  city_population       cpi  rev_total_city  \\\n",
       "0  1977  AK: Anchorage  22002001.0           174500  4.044885         5342.24   \n",
       "1  1978  AK: Anchorage  22002001.0           177000  3.759509         5948.99   \n",
       "\n",
       "   rev_general_city  intergovt_rev_city  igr_federal_city  igr_state_city  \\\n",
       "0           4956.92             2148.77            279.32         1869.46   \n",
       "1           5490.05             2468.11            403.24         2064.86   \n",
       "\n",
       "   ...  cash_other_offsets  cash_other_bonds  cash_other_other  county_name  \\\n",
       "0  ...              178.51            787.93            691.32          NaN   \n",
       "1  ...              187.53           1395.82           1158.01          NaN   \n",
       "\n",
       "   id_county  county_population  relationship_city_school  enrollment  \\\n",
       "0        NaN                NaN                       4.0     36855.0   \n",
       "1        NaN                NaN                       4.0     36804.0   \n",
       "\n",
       "   districts_in_city  consolidated_govt  \n",
       "0                NaN                1.0  \n",
       "1                NaN                1.0  \n",
       "\n",
       "[2 rows x 662 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budgets_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                        6232\n",
       "city_name                   6232\n",
       "id_city                     6191\n",
       "city_population             6232\n",
       "cpi                         6150\n",
       "                            ... \n",
       "county_population           5418\n",
       "relationship_city_school    6150\n",
       "enrollment                  6196\n",
       "districts_in_city           4741\n",
       "consolidated_govt           6150\n",
       "Length: 662, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budgets_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given that year, city_name and city_population all have the same number of records, I should simply check if there are any duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6232"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(budgets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                          41\n",
       "city_name                    152\n",
       "id_city                      151\n",
       "city_population             6145\n",
       "cpi                           41\n",
       "                            ... \n",
       "county_population           4995\n",
       "relationship_city_school       5\n",
       "enrollment                  5108\n",
       "districts_in_city             22\n",
       "consolidated_govt              2\n",
       "Length: 662, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budgets_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "budgets_df =budgets_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6232"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(budgets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>city_name</th>\n",
       "      <th>id_city</th>\n",
       "      <th>city_population</th>\n",
       "      <th>cpi</th>\n",
       "      <th>rev_total_city</th>\n",
       "      <th>rev_general_city</th>\n",
       "      <th>intergovt_rev_city</th>\n",
       "      <th>igr_federal_city</th>\n",
       "      <th>igr_state_city</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_other_offsets</th>\n",
       "      <th>cash_other_bonds</th>\n",
       "      <th>cash_other_other</th>\n",
       "      <th>county_name</th>\n",
       "      <th>id_county</th>\n",
       "      <th>county_population</th>\n",
       "      <th>relationship_city_school</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>districts_in_city</th>\n",
       "      <th>consolidated_govt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1977</td>\n",
       "      <td>Average for Cities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2312.35</td>\n",
       "      <td>1889.98</td>\n",
       "      <td>760.76</td>\n",
       "      <td>338.25</td>\n",
       "      <td>422.51</td>\n",
       "      <td>...</td>\n",
       "      <td>366.03</td>\n",
       "      <td>387.54</td>\n",
       "      <td>839.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690459.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59844.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1978</td>\n",
       "      <td>Average for Cities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>349355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2290.69</td>\n",
       "      <td>1846.08</td>\n",
       "      <td>696.37</td>\n",
       "      <td>360.90</td>\n",
       "      <td>335.47</td>\n",
       "      <td>...</td>\n",
       "      <td>495.97</td>\n",
       "      <td>403.98</td>\n",
       "      <td>869.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>696845.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64642.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1979</td>\n",
       "      <td>Average for Cities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2256.35</td>\n",
       "      <td>1816.53</td>\n",
       "      <td>693.98</td>\n",
       "      <td>352.31</td>\n",
       "      <td>341.68</td>\n",
       "      <td>...</td>\n",
       "      <td>302.54</td>\n",
       "      <td>461.02</td>\n",
       "      <td>893.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>704711.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56383.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 662 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year           city_name  id_city  city_population  cpi  rev_total_city  \\\n",
       "410  1977  Average for Cities      NaN           350083  NaN         2312.35   \n",
       "411  1978  Average for Cities      NaN           349355  NaN         2290.69   \n",
       "412  1979  Average for Cities      NaN           348967  NaN         2256.35   \n",
       "\n",
       "     rev_general_city  intergovt_rev_city  igr_federal_city  igr_state_city  \\\n",
       "410           1889.98              760.76            338.25          422.51   \n",
       "411           1846.08              696.37            360.90          335.47   \n",
       "412           1816.53              693.98            352.31          341.68   \n",
       "\n",
       "     ...  cash_other_offsets  cash_other_bonds  cash_other_other  county_name  \\\n",
       "410  ...              366.03            387.54            839.45          NaN   \n",
       "411  ...              495.97            403.98            869.54          NaN   \n",
       "412  ...              302.54            461.02            893.65          NaN   \n",
       "\n",
       "     id_county  county_population  relationship_city_school  enrollment  \\\n",
       "410        NaN           690459.0                       NaN     59844.0   \n",
       "411        NaN           696845.0                       NaN     64642.0   \n",
       "412        NaN           704711.0                       NaN     56383.0   \n",
       "\n",
       "     districts_in_city  consolidated_govt  \n",
       "410                NaN                NaN  \n",
       "411                NaN                NaN  \n",
       "412                NaN                NaN  \n",
       "\n",
       "[3 rows x 662 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I previously noticed that some records don't have id_city. I want to know what kind information do these records hold\n",
    "budgets_df[budgets_df.id_city.isnull()].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Okay, those records show data average for cities. I don't need them and I will drop these records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "budgets_df_cleaned = budgets_df[budgets_df.id_city.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                        6191\n",
       "city_name                   6191\n",
       "id_city                     6191\n",
       "city_population             6191\n",
       "cpi                         6150\n",
       "                            ... \n",
       "county_population           5377\n",
       "relationship_city_school    6150\n",
       "enrollment                  6155\n",
       "districts_in_city           4741\n",
       "consolidated_govt           6150\n",
       "Length: 662, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budgets_df_cleaned.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data looks a lot cleaner now. I don't want to use the dropna function because it looks like the issues come from some missing data in te county_name, id_county, enrollment, consolidated_govt and districts_in_city columns. I won't use these columns anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>city_name</th>\n",
       "      <th>id_city</th>\n",
       "      <th>city_population</th>\n",
       "      <th>cpi</th>\n",
       "      <th>rev_total_city</th>\n",
       "      <th>rev_general_city</th>\n",
       "      <th>intergovt_rev_city</th>\n",
       "      <th>igr_federal_city</th>\n",
       "      <th>igr_state_city</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_other_offsets</th>\n",
       "      <th>cash_other_bonds</th>\n",
       "      <th>cash_other_other</th>\n",
       "      <th>county_name</th>\n",
       "      <th>id_county</th>\n",
       "      <th>county_population</th>\n",
       "      <th>relationship_city_school</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>districts_in_city</th>\n",
       "      <th>consolidated_govt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1977</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>174500</td>\n",
       "      <td>4.044885</td>\n",
       "      <td>5342.24</td>\n",
       "      <td>4956.92</td>\n",
       "      <td>2148.77</td>\n",
       "      <td>279.32</td>\n",
       "      <td>1869.46</td>\n",
       "      <td>...</td>\n",
       "      <td>178.51</td>\n",
       "      <td>787.93</td>\n",
       "      <td>691.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36855.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 662 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      city_name     id_city  city_population       cpi  rev_total_city  \\\n",
       "0  1977  AK: Anchorage  22002001.0           174500  4.044885         5342.24   \n",
       "\n",
       "   rev_general_city  intergovt_rev_city  igr_federal_city  igr_state_city  \\\n",
       "0           4956.92             2148.77            279.32         1869.46   \n",
       "\n",
       "   ...  cash_other_offsets  cash_other_bonds  cash_other_other  county_name  \\\n",
       "0  ...              178.51            787.93            691.32          NaN   \n",
       "\n",
       "   id_county  county_population  relationship_city_school  enrollment  \\\n",
       "0        NaN                NaN                       4.0     36855.0   \n",
       "\n",
       "   districts_in_city  consolidated_govt  \n",
       "0                NaN                1.0  \n",
       "\n",
       "[1 rows x 662 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budgets_df_cleaned.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6191"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(budgets_df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I want to drop the index column as that column shows inaccurate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "budgets_df_cleaned =budgets_df_cleaned.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>city_name</th>\n",
       "      <th>id_city</th>\n",
       "      <th>city_population</th>\n",
       "      <th>cpi</th>\n",
       "      <th>rev_total_city</th>\n",
       "      <th>rev_general_city</th>\n",
       "      <th>intergovt_rev_city</th>\n",
       "      <th>igr_federal_city</th>\n",
       "      <th>igr_state_city</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_other_offsets</th>\n",
       "      <th>cash_other_bonds</th>\n",
       "      <th>cash_other_other</th>\n",
       "      <th>county_name</th>\n",
       "      <th>id_county</th>\n",
       "      <th>county_population</th>\n",
       "      <th>relationship_city_school</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>districts_in_city</th>\n",
       "      <th>consolidated_govt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1977</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>174500</td>\n",
       "      <td>4.044885</td>\n",
       "      <td>5342.24</td>\n",
       "      <td>4956.92</td>\n",
       "      <td>2148.77</td>\n",
       "      <td>279.32</td>\n",
       "      <td>1869.46</td>\n",
       "      <td>...</td>\n",
       "      <td>178.51</td>\n",
       "      <td>787.93</td>\n",
       "      <td>691.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36855.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>177000</td>\n",
       "      <td>3.759509</td>\n",
       "      <td>5948.99</td>\n",
       "      <td>5490.05</td>\n",
       "      <td>2468.11</td>\n",
       "      <td>403.24</td>\n",
       "      <td>2064.86</td>\n",
       "      <td>...</td>\n",
       "      <td>187.53</td>\n",
       "      <td>1395.82</td>\n",
       "      <td>1158.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36804.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 662 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      city_name     id_city  city_population       cpi  rev_total_city  \\\n",
       "0  1977  AK: Anchorage  22002001.0           174500  4.044885         5342.24   \n",
       "1  1978  AK: Anchorage  22002001.0           177000  3.759509         5948.99   \n",
       "\n",
       "   rev_general_city  intergovt_rev_city  igr_federal_city  igr_state_city  \\\n",
       "0           4956.92             2148.77            279.32         1869.46   \n",
       "1           5490.05             2468.11            403.24         2064.86   \n",
       "\n",
       "   ...  cash_other_offsets  cash_other_bonds  cash_other_other  county_name  \\\n",
       "0  ...              178.51            787.93            691.32          NaN   \n",
       "1  ...              187.53           1395.82           1158.01          NaN   \n",
       "\n",
       "   id_county  county_population  relationship_city_school  enrollment  \\\n",
       "0        NaN                NaN                       4.0     36855.0   \n",
       "1        NaN                NaN                       4.0     36804.0   \n",
       "\n",
       "   districts_in_city  consolidated_govt  \n",
       "0                NaN                1.0  \n",
       "1                NaN                1.0  \n",
       "\n",
       "[2 rows x 662 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budgets_df_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now I am going to create a dataset with the popultion information only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_population = budgets_df_cleaned[['year','city_name','id_city','city_population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>city_name</th>\n",
       "      <th>id_city</th>\n",
       "      <th>city_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1977</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>174500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>177000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      city_name     id_city  city_population\n",
       "0  1977  AK: Anchorage  22002001.0           174500\n",
       "1  1978  AK: Anchorage  22002001.0           177000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_population.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wtong/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "city_population[\"state\"]= city_population[\"city_name\"].str.split(\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>city_name</th>\n",
       "      <th>id_city</th>\n",
       "      <th>city_population</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1977</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>174500</td>\n",
       "      <td>[AK,  Anchorage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>177000</td>\n",
       "      <td>[AK,  Anchorage]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      city_name     id_city  city_population             state\n",
       "0  1977  AK: Anchorage  22002001.0           174500  [AK,  Anchorage]\n",
       "1  1978  AK: Anchorage  22002001.0           177000  [AK,  Anchorage]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_population.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wtong/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "city_population[\"state\"]= city_population[\"city_name\"].str.split(\":\",n=1,expand= True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>city_name</th>\n",
       "      <th>id_city</th>\n",
       "      <th>city_population</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1977</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>174500</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>22002001.0</td>\n",
       "      <td>177000</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      city_name     id_city  city_population state\n",
       "0  1977  AK: Anchorage  22002001.0           174500    AK\n",
       "1  1978  AK: Anchorage  22002001.0           177000    AK"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_population.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6191"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(city_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>city_name</th>\n",
       "      <th>id_city</th>\n",
       "      <th>city_population</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IA</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KS</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KY</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MS</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median for Cities</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ND</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NV</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NY</th>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OK</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RI</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX</th>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UT</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VA</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WA</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WV</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   year  city_name  id_city  city_population  state\n",
       "state                                                              \n",
       "AK                   41          2        2               82      1\n",
       "AL                   41          3        3              123      1\n",
       "AR                   41          2        2               82      1\n",
       "AZ                   41          3        3              123      1\n",
       "CA                   41         16       16              656      1\n",
       "CO                   41          3        3              122      1\n",
       "CT                   41          3        3              123      1\n",
       "DC                   41          1        1               41      1\n",
       "DE                   41          2        2               79      1\n",
       "FL                   41          8        8              328      1\n",
       "GA                   41          2        2               82      1\n",
       "IA                   41          2        2               82      1\n",
       "ID                   41          2        2               82      1\n",
       "IL                   41          2        2               82      1\n",
       "IN                   41          3        3              123      1\n",
       "KS                   41          3        3              123      1\n",
       "KY                   41          2        2               82      1\n",
       "LA                   41          3        3              123      1\n",
       "MA                   41          3        3              123      1\n",
       "MD                   41          2        2               82      1\n",
       "ME                   41          2        2               82      1\n",
       "MI                   41          4        4              164      1\n",
       "MN                   41          2        2               82      1\n",
       "MO                   41          2        2               82      1\n",
       "MS                   41          2        2               82      1\n",
       "MT                   41          2        2               82      1\n",
       "Median for Cities    41          1        1               41      1\n",
       "NC                   41          4        4              164      1\n",
       "ND                   41          2        2               82      1\n",
       "NE                   41          2        2               82      1\n",
       "NH                   41          2        2               82      1\n",
       "NM                   41          2        2               82      1\n",
       "NV                   41          2        2               82      1\n",
       "NY                   41          5        5              205      1\n",
       "OH                   41          6        6              246      1\n",
       "OK                   41          2        2               82      1\n",
       "OR                   41          3        3              123      1\n",
       "PA                   41          2        2               82      1\n",
       "RI                   41          2        2               82      1\n",
       "SC                   41          2        2               82      1\n",
       "SD                   41          2        2               82      1\n",
       "TN                   41          4        4              164      1\n",
       "TX                   41         10       10              410      1\n",
       "UT                   41          2        2               82      1\n",
       "VA                   41          4        4              163      1\n",
       "VT                   41          2        2               81      1\n",
       "WA                   41          3        3              123      1\n",
       "WI                   41          2        2               82      1\n",
       "WV                   41          2        2               82      1\n",
       "WY                   41          2        2               82      1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_population.groupby('state').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I noticed that this dataset has median values for cities, which I don't want. So I am going to delete these records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year               41\n",
       "city_name          41\n",
       "id_city            41\n",
       "city_population    41\n",
       "state              41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_population.query('state == \"Median for Cities\"').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After deleting the 41 records, I should expect to 6150 records in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_population = city_population.query('state != \"Median for Cities\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6150"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(city_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_population_file = 'city_population.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3path = 's3://datalake-blm/stage/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#city_population.to_csv(city_population_s3, index = False)\n",
    "city_population.to_csv(os.path.join(s3path, city_population_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.3'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Police Killings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Victim's name</th>\n",
       "      <th>Victim's age</th>\n",
       "      <th>Victim's gender</th>\n",
       "      <th>Victim's race</th>\n",
       "      <th>URL of image of victim</th>\n",
       "      <th>Date of Incident (month/day/year)</th>\n",
       "      <th>Street Address of Incident</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 56</th>\n",
       "      <th>Unnamed: 57</th>\n",
       "      <th>Unnamed: 58</th>\n",
       "      <th>Unnamed: 59</th>\n",
       "      <th>Unnamed: 60</th>\n",
       "      <th>Unnamed: 61</th>\n",
       "      <th>Unnamed: 62</th>\n",
       "      <th>Unnamed: 63</th>\n",
       "      <th>Unnamed: 64</th>\n",
       "      <th>Unnamed: 65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eric M. Tellez</td>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>https://fatalencounters.org/wp-content/uploads...</td>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>Broad St.</td>\n",
       "      <td>Globe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85501.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name withheld by police</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>7239-7411 I-40</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>AR</td>\n",
       "      <td>38103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Victim's name Victim's age Victim's gender Victim's race  \\\n",
       "0           Eric M. Tellez           28            Male         White   \n",
       "1  Name withheld by police          NaN            Male  Unknown race   \n",
       "\n",
       "                              URL of image of victim  \\\n",
       "0  https://fatalencounters.org/wp-content/uploads...   \n",
       "1                                                NaN   \n",
       "\n",
       "  Date of Incident (month/day/year) Street Address of Incident     City State  \\\n",
       "0                        31/12/2019                 Broad St.     Globe    AZ   \n",
       "1                        31/12/2019             7239-7411 I-40  Memphis    AR   \n",
       "\n",
       "   Zipcode     ...     Unnamed: 56 Unnamed: 57 Unnamed: 58 Unnamed: 59  \\\n",
       "0  85501.0     ...             NaN         NaN         NaN         NaN   \n",
       "1  38103.0     ...             NaN         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 60 Unnamed: 61 Unnamed: 62 Unnamed: 63 Unnamed: 64 Unnamed: 65  \n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[2 rows x 66 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7907"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(police_killings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_killings_cleaned = police_killings_df[[\"Victim's name\", \"Victim's age\", \"Victim's gender\",\"Victim's race\",\"URL of image of victim\",\"Date of Incident (month/day/year)\",\"Street Address of Incident\"\\\n",
    "                                             ,\"City\",\"State\",\"Zipcode\",\"County\",\"Agency responsible for death\",\"Cause of death\",\"A brief description of the circumstances surrounding the death\"\\\n",
    "                                             ,\"Official disposition of death (justified or other)\",\"Criminal Charges?\",\"Link to news article or photo of official document\",\"Symptoms of mental illness?\"\\\n",
    "                                             ,\"Unarmed\",\"Alleged Weapon (Source: WaPo)\",\"Alleged Threat Level (Source: WaPo)\",\"Fleeing (Source: WaPo)\",\"Body Camera (Source: WaPo)\",\"WaPo ID (If included in WaPo database)\"\\\n",
    "                                             ,\"Off-Duty Killing?\",\"Geography (via Trulia methodology based on zipcode population density: http://jedkolko.com/wp-content/uploads/2015/05/full-ZCTA-urban-suburban-rural-classification.xlsx )\"\\\n",
    "                                             ,\"ID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Victim's name                                                                                                                                                                 7663\n",
       "Victim's age                                                                                                                                                                  7596\n",
       "Victim's gender                                                                                                                                                               7655\n",
       "Victim's race                                                                                                                                                                 7663\n",
       "URL of image of victim                                                                                                                                                        4200\n",
       "Date of Incident (month/day/year)                                                                                                                                             7663\n",
       "Street Address of Incident                                                                                                                                                    7580\n",
       "City                                                                                                                                                                          7657\n",
       "State                                                                                                                                                                         7663\n",
       "Zipcode                                                                                                                                                                       7624\n",
       "County                                                                                                                                                                        7648\n",
       "Agency responsible for death                                                                                                                                                  7647\n",
       "Cause of death                                                                                                                                                                7663\n",
       "A brief description of the circumstances surrounding the death                                                                                                                7643\n",
       "Official disposition of death (justified or other)                                                                                                                            7407\n",
       "Criminal Charges?                                                                                                                                                             7663\n",
       "Link to news article or photo of official document                                                                                                                            7651\n",
       "Symptoms of mental illness?                                                                                                                                                   7652\n",
       "Unarmed                                                                                                                                                                       7663\n",
       "Alleged Weapon (Source: WaPo)                                                                                                                                                 7663\n",
       "Alleged Threat Level (Source: WaPo)                                                                                                                                           5281\n",
       "Fleeing (Source: WaPo)                                                                                                                                                        5047\n",
       "Body Camera (Source: WaPo)                                                                                                                                                    4794\n",
       "WaPo ID (If included in WaPo database)                                                                                                                                        4878\n",
       "Off-Duty Killing?                                                                                                                                                              226\n",
       "Geography (via Trulia methodology based on zipcode population density: http://jedkolko.com/wp-content/uploads/2015/05/full-ZCTA-urban-suburban-rural-classification.xlsx )    7596\n",
       "ID                                                                                                                                                                            7663\n",
       "dtype: int64"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Victim's name</th>\n",
       "      <th>Victim's age</th>\n",
       "      <th>Victim's gender</th>\n",
       "      <th>Victim's race</th>\n",
       "      <th>URL of image of victim</th>\n",
       "      <th>Date of Incident (month/day/year)</th>\n",
       "      <th>Street Address of Incident</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Symptoms of mental illness?</th>\n",
       "      <th>Unarmed</th>\n",
       "      <th>Alleged Weapon (Source: WaPo)</th>\n",
       "      <th>Alleged Threat Level (Source: WaPo)</th>\n",
       "      <th>Fleeing (Source: WaPo)</th>\n",
       "      <th>Body Camera (Source: WaPo)</th>\n",
       "      <th>WaPo ID (If included in WaPo database)</th>\n",
       "      <th>Off-Duty Killing?</th>\n",
       "      <th>Geography (via Trulia methodology based on zipcode population density: http://jedkolko.com/wp-content/uploads/2015/05/full-ZCTA-urban-suburban-rural-classification.xlsx )</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eric M. Tellez</td>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>https://fatalencounters.org/wp-content/uploads...</td>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>Broad St.</td>\n",
       "      <td>Globe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85501.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Allegedly Armed</td>\n",
       "      <td>knife</td>\n",
       "      <td>other</td>\n",
       "      <td>not fleeing</td>\n",
       "      <td>no</td>\n",
       "      <td>5332.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>7664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name withheld by police</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>7239-7411 I-40</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>AR</td>\n",
       "      <td>38103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>unclear</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban</td>\n",
       "      <td>7665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Terry Hudson</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>3600 N 24th St</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>NE</td>\n",
       "      <td>68110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Allegedly Armed</td>\n",
       "      <td>gun</td>\n",
       "      <td>attack</td>\n",
       "      <td>not fleeing</td>\n",
       "      <td>no</td>\n",
       "      <td>5359.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban</td>\n",
       "      <td>7661.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Victim's name Victim's age Victim's gender Victim's race  \\\n",
       "0           Eric M. Tellez           28            Male         White   \n",
       "1  Name withheld by police          NaN            Male  Unknown race   \n",
       "2             Terry Hudson           57            Male         Black   \n",
       "\n",
       "                              URL of image of victim  \\\n",
       "0  https://fatalencounters.org/wp-content/uploads...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "\n",
       "  Date of Incident (month/day/year) Street Address of Incident     City State  \\\n",
       "0                        31/12/2019                 Broad St.     Globe    AZ   \n",
       "1                        31/12/2019             7239-7411 I-40  Memphis    AR   \n",
       "2                        31/12/2019             3600 N 24th St    Omaha    NE   \n",
       "\n",
       "   Zipcode   ...   Symptoms of mental illness?          Unarmed  \\\n",
       "0  85501.0   ...                            No  Allegedly Armed   \n",
       "1  38103.0   ...                            No          Unclear   \n",
       "2  68110.0   ...                            No  Allegedly Armed   \n",
       "\n",
       "  Alleged Weapon (Source: WaPo) Alleged Threat Level (Source: WaPo)  \\\n",
       "0                         knife                               other   \n",
       "1                       unclear                               other   \n",
       "2                           gun                              attack   \n",
       "\n",
       "  Fleeing (Source: WaPo) Body Camera (Source: WaPo)  \\\n",
       "0            not fleeing                         no   \n",
       "1                    NaN                        NaN   \n",
       "2            not fleeing                         no   \n",
       "\n",
       "  WaPo ID (If included in WaPo database) Off-Duty Killing?  \\\n",
       "0                                 5332.0               NaN   \n",
       "1                                    NaN               NaN   \n",
       "2                                 5359.0               NaN   \n",
       "\n",
       "  Geography (via Trulia methodology based on zipcode population density: http://jedkolko.com/wp-content/uploads/2015/05/full-ZCTA-urban-suburban-rural-classification.xlsx )  \\\n",
       "0                                              Rural                                                                                                                           \n",
       "1                                              Urban                                                                                                                           \n",
       "2                                              Urban                                                                                                                           \n",
       "\n",
       "       ID  \n",
       "0  7664.0  \n",
       "1  7665.0  \n",
       "2  7661.0  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The names of columns are long and messy, I am going to tidy them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = {\n",
    "   \"Victim's name\":\"victim_name\",\n",
    "   \"Victim's age\":\"victim_age\",\n",
    "   \"Victim's race\":\"victim_race\",\n",
    "   \"Victim's gender\":\"victim_gender\",\n",
    "   \"URL of image of victim\":\"victim_image\",\n",
    "   \"Date of Incident (month/day/year)\":\"date_of_incident\",\n",
    "   \"Street Address of Incident\":\"street_address_of_incident\",\n",
    "   \"City\":\"city\",\n",
    "   \"State\":\"state\",\n",
    "   \"Zipcode\":\"zipcode\",\n",
    "   \"Symptoms of mental illness?\": \"has_symtoms_of_mental_ilness\",\n",
    "   \"Unarmed\":'unarmed',\n",
    "   \"Alleged Weapon (Source: WaPo)\":\"alleged_weapon\",\n",
    "   \"Alleged Threat Level (Source: WaPo)\":\"alleged_threat_level\",\n",
    "   \"Fleeing (Source: WaPo)\":\"fleeing\",\n",
    "   \"Body Camera (Source: WaPo)\":\"body_camera\",\n",
    "   \"WaPo ID (If included in WaPo database)\":\"wapo_id\",\n",
    "   \"Off-Duty Killing?\":\"is_off_duty_killing\",\n",
    "   \"Geography (via Trulia methodology based on zipcode population density: http://jedkolko.com/wp-content/uploads/2015/05/full-ZCTA-urban-suburban-rural-classification.xlsx )\":\"geography\",\n",
    "   \"ID\":\"id\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_killings_cleaned = police_killings_cleaned.rename(columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>victim_name</th>\n",
       "      <th>victim_age</th>\n",
       "      <th>victim_gender</th>\n",
       "      <th>victim_race</th>\n",
       "      <th>victim_image</th>\n",
       "      <th>date_of_incident</th>\n",
       "      <th>street_address_of_incident</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>...</th>\n",
       "      <th>has_symtoms_of_mental_ilness</th>\n",
       "      <th>unarmed</th>\n",
       "      <th>alleged_weapon</th>\n",
       "      <th>alleged_threat_level</th>\n",
       "      <th>fleeing</th>\n",
       "      <th>body_camera</th>\n",
       "      <th>wapo_id</th>\n",
       "      <th>is_off_duty_killing</th>\n",
       "      <th>geography</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eric M. Tellez</td>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>https://fatalencounters.org/wp-content/uploads...</td>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>Broad St.</td>\n",
       "      <td>Globe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85501.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Allegedly Armed</td>\n",
       "      <td>knife</td>\n",
       "      <td>other</td>\n",
       "      <td>not fleeing</td>\n",
       "      <td>no</td>\n",
       "      <td>5332.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>7664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name withheld by police</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>7239-7411 I-40</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>AR</td>\n",
       "      <td>38103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>unclear</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban</td>\n",
       "      <td>7665.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               victim_name victim_age victim_gender   victim_race  \\\n",
       "0           Eric M. Tellez         28          Male         White   \n",
       "1  Name withheld by police        NaN          Male  Unknown race   \n",
       "\n",
       "                                        victim_image date_of_incident  \\\n",
       "0  https://fatalencounters.org/wp-content/uploads...       31/12/2019   \n",
       "1                                                NaN       31/12/2019   \n",
       "\n",
       "  street_address_of_incident     city state  zipcode   ...    \\\n",
       "0                 Broad St.     Globe    AZ  85501.0   ...     \n",
       "1             7239-7411 I-40  Memphis    AR  38103.0   ...     \n",
       "\n",
       "  has_symtoms_of_mental_ilness          unarmed alleged_weapon  \\\n",
       "0                           No  Allegedly Armed          knife   \n",
       "1                           No          Unclear        unclear   \n",
       "\n",
       "  alleged_threat_level      fleeing body_camera wapo_id is_off_duty_killing  \\\n",
       "0                other  not fleeing          no  5332.0                 NaN   \n",
       "1                other          NaN         NaN     NaN                 NaN   \n",
       "\n",
       "  geography      id  \n",
       "0     Rural  7664.0  \n",
       "1     Urban  7665.0  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "victim_name                                                       210\n",
       "victim_age                                                        154\n",
       "victim_gender                                                     205\n",
       "victim_race                                                       210\n",
       "victim_image                                                        0\n",
       "date_of_incident                                                  210\n",
       "street_address_of_incident                                        198\n",
       "city                                                              209\n",
       "state                                                             210\n",
       "zipcode                                                           204\n",
       "County                                                            205\n",
       "Agency responsible for death                                      205\n",
       "Cause of death                                                    210\n",
       "A brief description of the circumstances surrounding the death    205\n",
       "Official disposition of death (justified or other)                206\n",
       "Criminal Charges?                                                 210\n",
       "Link to news article or photo of official document                205\n",
       "has_symtoms_of_mental_ilness                                      207\n",
       "unarmed                                                           210\n",
       "alleged_weapon                                                    210\n",
       "alleged_threat_level                                              147\n",
       "fleeing                                                           132\n",
       "body_camera                                                       117\n",
       "wapo_id                                                           120\n",
       "is_off_duty_killing                                                 9\n",
       "geography                                                         204\n",
       "id                                                                210\n",
       "dtype: int64"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.query(\"victim_name == 'Name withheld by police'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AZ', 'AR', 'NE', 'WA', 'MO', 'WV', 'MS', 'KS', 'TX', 'CA', 'SD',\n",
       "       'IN', 'AK', 'OH', 'TN', 'MD', 'VA', 'UT', 'ME', 'FL', 'GA', 'OK',\n",
       "       'PA', 'NY', 'NC', 'CO', 'MT', 'HI', 'WI', 'MN', 'MI', 'AL', 'SC',\n",
       "       'NJ', 'IA', 'LA', 'OR', 'DE', 'NV', 'IL', 'ID', 'MA', 'KY', 'NM',\n",
       "       'VT', 'WY', 'DC', 'CT', 'NH', 'RI', 'ND', nan], dtype=object)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.state.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>victim_name</th>\n",
       "      <th>victim_age</th>\n",
       "      <th>victim_gender</th>\n",
       "      <th>victim_race</th>\n",
       "      <th>victim_image</th>\n",
       "      <th>date_of_incident</th>\n",
       "      <th>street_address_of_incident</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>...</th>\n",
       "      <th>has_symtoms_of_mental_ilness</th>\n",
       "      <th>unarmed</th>\n",
       "      <th>alleged_weapon</th>\n",
       "      <th>alleged_threat_level</th>\n",
       "      <th>fleeing</th>\n",
       "      <th>body_camera</th>\n",
       "      <th>wapo_id</th>\n",
       "      <th>is_off_duty_killing</th>\n",
       "      <th>geography</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7666</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7670</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7671</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7672</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7673</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7674</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7675</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7676</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7677</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7678</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7679</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7680</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7681</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7682</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     victim_name victim_age victim_gender victim_race victim_image  \\\n",
       "7663         NaN        NaN           NaN         NaN          NaN   \n",
       "7664         NaN        NaN           NaN         NaN          NaN   \n",
       "7665         NaN        NaN           NaN         NaN          NaN   \n",
       "7666         NaN        NaN           NaN         NaN          NaN   \n",
       "7667         NaN        NaN           NaN         NaN          NaN   \n",
       "7668         NaN        NaN           NaN         NaN          NaN   \n",
       "7669         NaN        NaN           NaN         NaN          NaN   \n",
       "7670         NaN        NaN           NaN         NaN          NaN   \n",
       "7671         NaN        NaN           NaN         NaN          NaN   \n",
       "7672         NaN        NaN           NaN         NaN          NaN   \n",
       "7673         NaN        NaN           NaN         NaN          NaN   \n",
       "7674         NaN        NaN           NaN         NaN          NaN   \n",
       "7675         NaN        NaN           NaN         NaN          NaN   \n",
       "7676         NaN        NaN           NaN         NaN          NaN   \n",
       "7677         NaN        NaN           NaN         NaN          NaN   \n",
       "7678         NaN        NaN           NaN         NaN          NaN   \n",
       "7679         NaN        NaN           NaN         NaN          NaN   \n",
       "7680         NaN        NaN           NaN         NaN          NaN   \n",
       "7681         NaN        NaN           NaN         NaN          NaN   \n",
       "7682         NaN        NaN           NaN         NaN          NaN   \n",
       "\n",
       "     date_of_incident street_address_of_incident city state  zipcode ...  \\\n",
       "7663              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7664              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7665              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7666              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7667              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7668              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7669              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7670              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7671              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7672              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7673              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7674              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7675              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7676              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7677              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7678              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7679              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7680              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7681              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "7682              NaN                        NaN  NaN   NaN      NaN ...   \n",
       "\n",
       "     has_symtoms_of_mental_ilness unarmed alleged_weapon alleged_threat_level  \\\n",
       "7663                          NaN     NaN            NaN                  NaN   \n",
       "7664                          NaN     NaN            NaN                  NaN   \n",
       "7665                          NaN     NaN            NaN                  NaN   \n",
       "7666                          NaN     NaN            NaN                  NaN   \n",
       "7667                          NaN     NaN            NaN                  NaN   \n",
       "7668                          NaN     NaN            NaN                  NaN   \n",
       "7669                          NaN     NaN            NaN                  NaN   \n",
       "7670                          NaN     NaN            NaN                  NaN   \n",
       "7671                          NaN     NaN            NaN                  NaN   \n",
       "7672                          NaN     NaN            NaN                  NaN   \n",
       "7673                          NaN     NaN            NaN                  NaN   \n",
       "7674                          NaN     NaN            NaN                  NaN   \n",
       "7675                          NaN     NaN            NaN                  NaN   \n",
       "7676                          NaN     NaN            NaN                  NaN   \n",
       "7677                          NaN     NaN            NaN                  NaN   \n",
       "7678                          NaN     NaN            NaN                  NaN   \n",
       "7679                          NaN     NaN            NaN                  NaN   \n",
       "7680                          NaN     NaN            NaN                  NaN   \n",
       "7681                          NaN     NaN            NaN                  NaN   \n",
       "7682                          NaN     NaN            NaN                  NaN   \n",
       "\n",
       "     fleeing body_camera wapo_id is_off_duty_killing geography  id  \n",
       "7663     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7664     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7665     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7666     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7667     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7668     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7669     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7670     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7671     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7672     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7673     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7674     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7675     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7676     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7677     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7678     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7679     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7680     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7681     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "7682     NaN         NaN     NaN                 NaN       NaN NaN  \n",
       "\n",
       "[20 rows x 27 columns]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned[(police_killings_cleaned.state.isnull())].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seems like all the records with no state also do not have any records in other columns. I will delete them too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_killings_cleaned = police_kpolice_killings_cleanedillings_cleaned[(police_killings_cleaned.state.notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7663"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(police_killings_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AZ', 'AR', 'NE', 'WA', 'MO', 'WV', 'MS', 'KS', 'TX', 'CA', 'SD',\n",
       "       'IN', 'AK', 'OH', 'TN', 'MD', 'VA', 'UT', 'ME', 'FL', 'GA', 'OK',\n",
       "       'PA', 'NY', 'NC', 'CO', 'MT', 'HI', 'WI', 'MN', 'MI', 'AL', 'SC',\n",
       "       'NJ', 'IA', 'LA', 'OR', 'DE', 'NV', 'IL', 'ID', 'MA', 'KY', 'NM',\n",
       "       'VT', 'WY', 'DC', 'CT', 'NH', 'RI', 'ND'], dtype=object)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.state.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is bizarre that it still has 51 states after deleting all the null values. I will park this for now but will map this dataset with the state_name dataset later to ensure there is no duplicated states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Female', nan, 'Transgender', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.victim_gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male           7253\n",
       "Female          391\n",
       "Transgender       7\n",
       "Unknown           4\n",
       "Name: victim_gender, dtype: int64"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.victim_gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Allegedly Armed', 'Unclear', 'Vehicle', 'Unarmed'], dtype=object)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.unarmed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Allegedly Armed    5428\n",
       "Unarmed            1073\n",
       "Unclear             649\n",
       "Vehicle             513\n",
       "Name: unarmed, dtype: int64"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.unarmed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Allegedly Armed', 'Unclear', 'Vehicle', 'Unarmed'], dtype=object)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.unarmed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White', 'Unknown Race', 'Black', 'Hispanic', 'Pacific Islander',\n",
       "       'Asian', 'Native American'], dtype=object)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.victim_race.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I will group 'Unknown race' and 'Unknown Race' together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_killings_cleaned.victim_race = police_killings_cleaned.victim_race.replace('Unknown race', 'Unknown Race')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White', 'Unknown Race', 'Black', 'Hispanic', 'Pacific Islander',\n",
       "       'Asian', 'Native American'], dtype=object)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.victim_race.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['other', 'attack', nan, 'undetermined'], dtype=object)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.alleged_threat_level.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attack          3395\n",
       "other           1595\n",
       "undetermined     291\n",
       "Name: alleged_threat_level, dtype: int64"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.alleged_threat_level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not fleeing', nan, 'car', 'Foot', 'Not fleeing', '0', 'foot',\n",
       "       'Car', 'Other'], dtype=object)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.fleeing.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not fleeing    3365\n",
       "Car             808\n",
       "Foot            632\n",
       "Other           144\n",
       "0                83\n",
       "not fleeing       8\n",
       "car               5\n",
       "foot              2\n",
       "Name: fleeing, dtype: int64"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.fleeing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>victim_name</th>\n",
       "      <th>victim_age</th>\n",
       "      <th>victim_gender</th>\n",
       "      <th>victim_race</th>\n",
       "      <th>victim_image</th>\n",
       "      <th>date_of_incident</th>\n",
       "      <th>street_address_of_incident</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>...</th>\n",
       "      <th>has_symtoms_of_mental_ilness</th>\n",
       "      <th>unarmed</th>\n",
       "      <th>alleged_weapon</th>\n",
       "      <th>alleged_threat_level</th>\n",
       "      <th>fleeing</th>\n",
       "      <th>body_camera</th>\n",
       "      <th>wapo_id</th>\n",
       "      <th>is_off_duty_killing</th>\n",
       "      <th>geography</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>John Bott</td>\n",
       "      <td>76</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29/12/2019</td>\n",
       "      <td>US-78</td>\n",
       "      <td>Byhalia</td>\n",
       "      <td>MS</td>\n",
       "      <td>38611.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Allegedly Armed</td>\n",
       "      <td>gun</td>\n",
       "      <td>undetermined</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>5310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>7654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Christopher Camacho</td>\n",
       "      <td>16</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27/12/2019</td>\n",
       "      <td>138 Washington St</td>\n",
       "      <td>Limerick</td>\n",
       "      <td>ME</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>undetermined</td>\n",
       "      <td>undetermined</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>5322.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>7647.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Antonio Smith</td>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>https://fatalencounters.org/wp-content/uploads...</td>\n",
       "      <td>26/12/2019</td>\n",
       "      <td>3600 Hallbrook St</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>TN</td>\n",
       "      <td>38127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>unknown weapon</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>5314.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>7643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gary Wayne Madewell</td>\n",
       "      <td>38</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>https://fatalencounters.org/wp-content/uploads...</td>\n",
       "      <td>19/12/2019</td>\n",
       "      <td>5 Boyd Ln</td>\n",
       "      <td>Carthage</td>\n",
       "      <td>TN</td>\n",
       "      <td>37030.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Allegedly Armed</td>\n",
       "      <td>knife</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>5294.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>7620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Dana Brown</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>Pacific Islander</td>\n",
       "      <td>https://fatalencounters.org/wp-content/uploads...</td>\n",
       "      <td>17/12/2019</td>\n",
       "      <td>Malakole Street</td>\n",
       "      <td>Kapolei</td>\n",
       "      <td>HI</td>\n",
       "      <td>96707.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Allegedly Armed</td>\n",
       "      <td>knife</td>\n",
       "      <td>attack</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>7616.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            victim_name victim_age victim_gender       victim_race  \\\n",
       "11            John Bott         76          Male      Unknown Race   \n",
       "23  Christopher Camacho         16          Male      Unknown Race   \n",
       "24        Antonio Smith         35          Male             Black   \n",
       "43  Gary Wayne Madewell         38          Male             White   \n",
       "54           Dana Brown         27          Male  Pacific Islander   \n",
       "\n",
       "                                         victim_image date_of_incident  \\\n",
       "11                                                NaN       29/12/2019   \n",
       "23                                                NaN       27/12/2019   \n",
       "24  https://fatalencounters.org/wp-content/uploads...       26/12/2019   \n",
       "43  https://fatalencounters.org/wp-content/uploads...       19/12/2019   \n",
       "54  https://fatalencounters.org/wp-content/uploads...       17/12/2019   \n",
       "\n",
       "   street_address_of_incident      city state  zipcode   ...    \\\n",
       "11                      US-78   Byhalia    MS  38611.0   ...     \n",
       "23          138 Washington St  Limerick    ME   4048.0   ...     \n",
       "24          3600 Hallbrook St   Memphis    TN  38127.0   ...     \n",
       "43                  5 Boyd Ln  Carthage    TN  37030.0   ...     \n",
       "54            Malakole Street   Kapolei    HI  96707.0   ...     \n",
       "\n",
       "   has_symtoms_of_mental_ilness          unarmed  alleged_weapon  \\\n",
       "11                      Unknown  Allegedly Armed             gun   \n",
       "23                           No          Unclear    undetermined   \n",
       "24                           No          Unclear  unknown weapon   \n",
       "43                           No  Allegedly Armed           knife   \n",
       "54                           No  Allegedly Armed           knife   \n",
       "\n",
       "   alleged_threat_level fleeing body_camera wapo_id is_off_duty_killing  \\\n",
       "11         undetermined       0          No  5310.0                 NaN   \n",
       "23         undetermined       0          No  5322.0                 NaN   \n",
       "24                other       0          No  5314.0                 NaN   \n",
       "43                other       0          No  5294.0                 NaN   \n",
       "54               attack       0         Yes  5290.0                 NaN   \n",
       "\n",
       "   geography      id  \n",
       "11     Rural  7654.0  \n",
       "23     Rural  7647.0  \n",
       "24  Suburban  7643.0  \n",
       "43     Rural  7620.0  \n",
       "54  Suburban  7616.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned[(police_killings_cleaned.fleeing == '0')].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are some duplicated values due to use of capital letters. I will tidy it up. I will also group '0' under 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_killings_cleaned.fleeing = police_killings_cleaned.fleeing.replace('not fleeing', 'Not fleeing')\n",
    "police_killings_cleaned.fleeing = police_killings_cleaned.fleeing.replace('car', 'Car')\n",
    "police_killings_cleaned.fleeing = police_killings_cleaned.fleeing.replace('foot', 'Foot')\n",
    "police_killings_cleaned.fleeing = police_killings_cleaned.fleeing.replace('0', 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not fleeing    3373\n",
       "Car             813\n",
       "Foot            634\n",
       "Other           227\n",
       "Name: fleeing, dtype: int64"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.fleeing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Off-Duty'], dtype=object)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.is_off_duty_killing.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.is_off_duty_killing.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['knife', 'unclear', 'gun', 'vehicle', 'chain', 'unknown weapon',\n",
       "       'Taser', 'undetermined', 'gun and vehicle', 'shovel', 'gun and car',\n",
       "       'toy weapon', 'unarmed', 'baseball bat', 'hatchet',\n",
       "       'car, knife and mace', 'sword', 'vehicle and machete',\n",
       "       'screwdriver', 'vehicle and gun', 'BB gun', 'sharp object',\n",
       "       'box cutter', 'ax', 'hammer', 'crowbar', 'chair', 'scissors', 'toy',\n",
       "       'baseball bat and knife', 'straight edge razor', 'machete', 'baton',\n",
       "       'Airsoft pistol', 'air pistol', 'wasp spray', 'BB gun and vehicle',\n",
       "       'piece of wood', 'gun and knife', 'garden tool', 'barstool',\n",
       "       'walking stick', 'wrench', 'beer bottle', 'meat cleaver',\n",
       "       'metal pipe', 'flag pole', 'rock', 'lawn mower blade', 'crossbow',\n",
       "       'metal object', 'bow and arrow', 'pick-axe', 'lamp', 'glass shard',\n",
       "       'incendiary device', 'unknown', 'pipe', 'pole and knife',\n",
       "       'Unknown weapon', 'lighter fluid', 'pitchfork', 'gun and sword',\n",
       "       'taser', 'blunt object', 'chainsaw', 'pen', 'fireworks',\n",
       "       'gun and hatchet', 'baseball bat and bottle',\n",
       "       'electric razor on cord', 'metal stick', 'golf club',\n",
       "       'pole and Knife', 'air conditioner and glass bottle', 'Scissors',\n",
       "       'tire iron', 'gun and machete', 'oar', 'bat', 'bottle',\n",
       "       'metal rake', 'brick', 'motorcycle', 'chain saw', 'bayonet',\n",
       "       'metal pole', 'Ax', 'spear', 'stick', 'knife, toy', 'flashlight',\n",
       "       'Pole', 'hand torch', 'baseball bat and fireplace poker',\n",
       "       'toy broomstick', 'bean-bag Gun', 'binoculars', 'Stapler',\n",
       "       'railroad spike', 'guns and explosives', \"contractor's level\",\n",
       "       'carjack', 'vehicle ', 'flagpole', 'metal hand tool',\n",
       "       'cordless drill', 'Hammer', 'nail gun', 'sock', 'edged weapon',\n",
       "       'wooden nightstand', 'knife and rocks', 'cell phone',\n",
       "       'baseball bat and screwdriver', 'metal bar', 'knife and crowbar',\n",
       "       'knife and screwdriver', 'axe', 'metal post', 'pepper spray',\n",
       "       'knives', 'toy sword', 'rocks', 'claw hammer', 'cologne',\n",
       "       'broken glass bottle', 'cane and knife', 'knife and stick', 'blade',\n",
       "       'gun and explosives', 'lighter', 'hockey stick', 'garden shears',\n",
       "       'gun ', 'wood stick ', 'knife and gun', 'ax and knife', 'cane',\n",
       "       'cleaver', 'game controller', 'screw driver', 'unclear weapon',\n",
       "       'guns', 'mallett', 'machete and pipe', 'knife and hammer',\n",
       "       'taser, baton, gun', 'hunting bow', 'wooden stick', 'unclear ',\n",
       "       'knife and bat', 'gun and knives', 'knife and taser',\n",
       "       'hammer and knife', 'knife and scissors', 'fireworks and gun',\n",
       "       'metal tool', 'explosives and guns', 'flare gun', 'knife/scissors',\n",
       "       'probe', 'tree branch', 'bike', 'table leg', 'unknown object',\n",
       "       'tool', 'gun, vehicle', 'sticks', 'hot glue gun', 'club',\n",
       "       'blunt weapon'], dtype=object)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.alleged_weapon.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are too many items in the weapon column. I am not going to tidy it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rural', 'Urban', 'Suburban', nan], dtype=object)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.geography.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_killings_cleaned.geography.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "victims_list = 'victims_list.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 's3://datalake-blm/stage/victims_list.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-475-d9a1250bda57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpolice_killings_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvictims_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mexcluded\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         rec.array([(1, 0.5 ), (2, 0.75)],\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \"\"\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;31m# Ensure the container is closed as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 's3://datalake-blm/stage/victims_list.csv'"
     ]
    }
   ],
   "source": [
    "police_killings_cleaned.to_csv(os.path.join(s3path, victims_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Police Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_deaths_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_deaths_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_deaths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Protest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- geometry: struct (nullable = true)\n",
      " |    |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- properties: struct (nullable = true)\n",
      " |    |    |    |-- Alias: string (nullable = true)\n",
      " |    |    |    |-- Batch: string (nullable = true)\n",
      " |    |    |    |-- City: string (nullable = true)\n",
      " |    |    |    |-- Comments: string (nullable = true)\n",
      " |    |    |    |-- Country: string (nullable = true)\n",
      " |    |    |    |-- Date_Added: long (nullable = true)\n",
      " |    |    |    |-- Mailing_Abbreviation: string (nullable = true)\n",
      " |    |    |    |-- OBJECTID: long (nullable = true)\n",
      " |    |    |    |-- Region: string (nullable = true)\n",
      " |    |    |    |-- Search_Label: string (nullable = true)\n",
      " |    |    |    |-- X_Longitude: double (nullable = true)\n",
      " |    |    |    |-- Y_Latitude: double (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "protests_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "# I am going to use spark explode function to flatten the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "protests_df_exploded = protests_df.select('type',explode('features').alias('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "protests_cleaned = protests_df_exploded.select(col('type').alias('featuretype'),'features.geometry.type','features.id','features.properties.Alias'\\\n",
    "                    ,'features.properties.Batch','features.properties.City','features.properties.Comments','features.properties.Country'\\\n",
    "                   ,'features.properties.Date_Added','features.properties.Mailing_Abbreviation','features.properties.OBJECTID'\\\n",
    "                   ,'features.properties.Region','features.properties.Search_Label','features.properties.X_Longitude','features.properties.Y_Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+---+-----+-----------+------------+--------+-------+-------------+--------------------+--------+--------+--------------------+-------------------+------------------+\n",
      "|      featuretype| type| id|Alias|      Batch|        City|Comments|Country|   Date_Added|Mailing_Abbreviation|OBJECTID|  Region|        Search_Label|        X_Longitude|        Y_Latitude|\n",
      "+-----------------+-----+---+-----+-----------+------------+--------+-------+-------------+--------------------+--------+--------+--------------------+-------------------+------------------+\n",
      "|FeatureCollection|Point|  1| null|2020_0602_1|      Juneau|    null|    USA|1591056000000|                  AK|       1|  Alaska| Juneau, Alaska, USA|-134.40678999999994| 58.29973000000007|\n",
      "|FeatureCollection|Point|  2| null|2020_0602_1|   Anchorage|    null|    USA|1591056000000|                  AK|       2|  Alaska|Anchorage, Alaska...|-149.85824999999997| 61.21753000000007|\n",
      "|FeatureCollection|Point|  3| null|2020_0602_1|   Fairbanks|    null|    USA|1591056000000|                  AK|       3|  Alaska|Fairbanks, Alaska...|-147.72209999999998| 64.84525000000008|\n",
      "|FeatureCollection|Point|  4| null|2020_0602_1|     Decatur|    null|    USA|1591056000000|                  AL|       4| Alabama|Decatur, Alabama,...| -86.97978999999998| 34.60740000000004|\n",
      "|FeatureCollection|Point|  5| null|2020_0602_1|      Dothan|    null|    USA|1591056000000|                  AL|       5| Alabama|Dothan, Alabama, USA| -85.39336999999995|31.223250000000064|\n",
      "|FeatureCollection|Point|  6| null|2020_0602_1|      Auburn|    null|    USA|1591056000000|                  AL|       6| Alabama|Auburn, Alabama, USA| -85.48172999999997| 32.60829000000007|\n",
      "|FeatureCollection|Point|  7| null|2020_0602_1|     Gadsden|    null|    USA|1591056000000|                  AL|       7| Alabama|Gadsden, Alabama,...| -86.00716999999997|34.014770000000055|\n",
      "|FeatureCollection|Point|  8| null|2020_0602_1|  Birmingham|    null|    USA|1591056000000|                  AL|       8| Alabama|Birmingham, Alaba...| -86.81175999999994| 33.52068000000003|\n",
      "|FeatureCollection|Point|  9| null|2020_0602_1|    Florence|    null|    USA|1591056000000|                  AL|       9| Alabama|Florence, Alabama...| -87.67488999999995| 34.80060000000003|\n",
      "|FeatureCollection|Point| 10| null|2020_0602_1|      Hoover|    null|    USA|1591056000000|                  AL|      10| Alabama|Hoover, Alabama, USA| -86.80602999999996| 33.38791000000003|\n",
      "|FeatureCollection|Point| 11| null|2020_0602_1|      Mobile|    null|    USA|1591056000000|                  AL|      11| Alabama|Mobile, Alabama, USA| -88.05296999999996|30.686480000000074|\n",
      "|FeatureCollection|Point| 12| null|2020_0602_1|     Opelika|    null|    USA|1591056000000|                  AL|      12| Alabama|Opelika, Alabama,...| -85.38064999999995| 32.65050000000008|\n",
      "|FeatureCollection|Point| 13| null|2020_0602_1|Jacksonville|    null|    USA|1591056000000|                  AL|      13| Alabama|Jacksonville, Ala...| -85.76117999999997|33.814220000000034|\n",
      "|FeatureCollection|Point| 14| null|2020_0602_1|  Huntsville|    null|    USA|1591056000000|                  AL|      14| Alabama|Huntsville, Alaba...| -86.58509999999995| 34.72929000000005|\n",
      "|FeatureCollection|Point| 15| null|2020_0602_1|        Troy|    null|    USA|1591056000000|                  AL|      15| Alabama|  Troy, Alabama, USA| -85.97216999999995| 31.80967000000004|\n",
      "|FeatureCollection|Point| 16| null|2020_0602_1|  Montgomery|    null|    USA|1591056000000|                  AL|      16| Alabama|Montgomery, Alaba...| -86.30007999999998| 32.38015000000007|\n",
      "|FeatureCollection|Point| 17| null|2020_0602_1|  Tuscaloosa|    null|    USA|1591056000000|                  AL|      17| Alabama|Tuscaloosa, Alaba...| -87.56624999999997|33.210420000000056|\n",
      "|FeatureCollection|Point| 18| null|2020_0602_1|      Conway|    null|    USA|1591056000000|                  AR|      18|Arkansas|Conway, Arkansas,...| -92.43968999999998| 35.09098000000006|\n",
      "|FeatureCollection|Point| 19| null|2020_0602_1|Fayetteville|    null|    USA|1591056000000|                  AR|      19|Arkansas|Fayetteville, Ark...| -94.15790999999996| 36.06320000000005|\n",
      "|FeatureCollection|Point| 20| null|2020_0602_1| Bentonville|    null|    USA|1591056000000|                  AR|      20|Arkansas|Bentonville, Arka...| -94.20948999999996|36.372330000000034|\n",
      "+-----------------+-----+---+-----+-----------+------------+--------+-------+-------------+--------------------+--------+--------+--------------------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "protests_cleaned.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- featuretype: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- Alias: string (nullable = true)\n",
      " |-- Batch: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Comments: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Date_Added: long (nullable = true)\n",
      " |-- Mailing_Abbreviation: string (nullable = true)\n",
      " |-- OBJECTID: long (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Search_Label: string (nullable = true)\n",
      " |-- X_Longitude: double (nullable = true)\n",
      " |-- Y_Latitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "protests_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month,dayofweek, dayofmonth, hour, weekofyear, date_format\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_timestamp = udf(lambda x: datetime.utcfromtimestamp(int(x)/1000), TimestampType())\n",
    "protests_cleaned = protests_cleaned.withColumn('Date_Added',get_timestamp('Date_Added'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o619.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 43.0 failed 1 times, most recent failure: Lost task 0.0 in stage 43.0 (TID 124, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 345, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 334, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 83, in <lambda>\n    return lambda *a: toInternal(f(*a))\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 77, in <lambda>\n    return lambda *a: g(f(*a))\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 77, in <lambda>\n    return lambda *a: g(f(*a))\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 77, in <lambda>\n    return lambda *a: g(f(*a))\n  File \"<ipython-input-490-c2a7cb457bb5>\", line 1, in <lambda>\nValueError: year 52388 is out of range\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3383)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2758)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.GeneratedMethodAccessor96.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 345, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 334, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 83, in <lambda>\n    return lambda *a: toInternal(f(*a))\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 77, in <lambda>\n    return lambda *a: g(f(*a))\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 77, in <lambda>\n    return lambda *a: g(f(*a))\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 77, in <lambda>\n    return lambda *a: g(f(*a))\n  File \"<ipython-input-490-c2a7cb457bb5>\", line 1, in <lambda>\nValueError: year 52388 is out of range\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-497-a6b46595bc77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprotests_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \"\"\"\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o619.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 43.0 failed 1 times, most recent failure: Lost task 0.0 in stage 43.0 (TID 124, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 345, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 334, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 83, in <lambda>\n    return lambda *a: toInternal(f(*a))\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 77, in <lambda>\n    return lambda *a: g(f(*a))\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 77, in <lambda>\n    return lambda *a: g(f(*a))\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 77, in <lambda>\n    return lambda *a: g(f(*a))\n  File \"<ipython-input-490-c2a7cb457bb5>\", line 1, in <lambda>\nValueError: year 52388 is out of range\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3383)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2758)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.GeneratedMethodAccessor96.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 345, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 334, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 83, in <lambda>\n    return lambda *a: toInternal(f(*a))\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 77, in <lambda>\n    return lambda *a: g(f(*a))\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 77, in <lambda>\n    return lambda *a: g(f(*a))\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 77, in <lambda>\n    return lambda *a: g(f(*a))\n  File \"<ipython-input-490-c2a7cb457bb5>\", line 1, in <lambda>\nValueError: year 52388 is out of range\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "protests_cleaned.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
